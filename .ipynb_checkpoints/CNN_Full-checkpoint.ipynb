{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Reshape, Permute, TimeDistributed, CuDNNLSTM,LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/livelab/Desktop/NewResizedBalanced/Training/' # directory containing subsets of data with labels\n",
    "valid_path = '/home/livelab/Desktop/NewResized/Validation/'\n",
    "test_path = '/home/livelab/Desktop/NewResized/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLayerNumByName(model, name):\n",
    "    layerList=model.layers\n",
    "    return layerList.index(model.get_layer(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_NUM = 30 # number of epochs to run\n",
    "LEARN_RATE = 0.01 # how much the guesses adjust for loss each time to find the minimum\n",
    "BATCH_SIZE = 64 # how many to process at once (greatest power of 2 that can ft in RAM)\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, \n",
    "                                                             shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', \n",
    "                                                             cval=0.0, horizontal_flip=True, vertical_flip=True)\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Use the ImageDataGenerators to load the training data\n",
    "train_gen = train_datagen.flow_from_directory(directory=train_path,\n",
    "                                    target_size=(256,256), # size to resize images to\n",
    "                                    color_mode='rgb', # color mode of the images\n",
    "                                    batch_size=BATCH_SIZE, # how many images to process at once\n",
    "                                    class_mode='categorical', # classify into categorical classes\n",
    "                                    shuffle=True # shuffle order of images\n",
    ")\n",
    "valid_gen = valid_datagen.flow_from_directory(directory=valid_path,\n",
    "                                    target_size=(256,256),\n",
    "                                    color_mode='rgb',\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=True\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(directory=test_path,\n",
    "                                    target_size=(256,256),\n",
    "                                    color_mode='rgb',\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full inception\n",
    "#freeze mix3 and prior\n",
    "inputData=Input(shape=(256, 256, 3))\n",
    "model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 256, 256, 3))\n",
    "# layer_name = 'mixed6'\n",
    "# index=findLayerNumByName(model, layer_name)\n",
    "# intermediate_model=Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer(layer_name).output)\n",
    "# for layer in intermediate_model.layers:\n",
    "#     layer.trainable = False\n",
    "intermediateOut = Flatten()(model.output)\n",
    "intermediateOut = Dense(32)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "prediction = Dense(24, activation='softmax')(intermediateOut)\n",
    "optmr = Adam(lr=0.0001, decay = 5e-4)\n",
    "model_final = Model(input = model.input, output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model-dev-finetune-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size/20\n",
    "STEP_SIZE_VALID=valid_gen.n//valid_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model_final.fit_generator(generator=train_gen,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN, # number of steps in each epoch\n",
    "                        validation_data=valid_gen,\n",
    "                        validation_steps=STEP_SIZE_VALID,\n",
    "                        callbacks=callbacks_list,\n",
    "                        epochs=EPOCH_NUM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(\"model-dev-05-0.53.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
    "# evaluate the function using the test set\n",
    "test_loss, test_acc = model_final.evaluate_generator(test_gen,\n",
    "                                            STEP_SIZE_TEST)\n",
    "\n",
    "# print test accuracy\n",
    "print('Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
