{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, './Preprocessing')\n",
    "import numpy as np\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from imgDataGenerator import *\n",
    "from preprocessing import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Reshape, Permute, TimeDistributed, CuDNNLSTM,LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.layers.merge import concatenate\n",
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[0,0,1]\n",
    "b=np.zeros((5,3))\n",
    "b[:,:]=a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dimension will be: #bag * #frame * 244 * 244 * 3\n",
    "#simple implementation of CNN>LSTM without multires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Check on Folder Succeed\n"
     ]
    }
   ],
   "source": [
    "#Note for Test, Training, and Validation folders, they all need to have same categories\n",
    "parentPath='/home/billy/Desktop/VideoClasBinned'\n",
    "checkAndGeneratePath(parentPath)\n",
    "testPath='/home/billy/Desktop/VideoClasBinned/Test'\n",
    "trainPath='/home/billy/Desktop/VideoClasBinned/Training'\n",
    "validPath='/home/billy/Desktop/VideoClasBinned/Validation'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingGen=imgDataGenerator(trainPath)\n",
    "validGen=imgDataGenerator(validPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo=prepdata(testPath)\n",
    "len(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/billy/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/billy/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#Using TimeDistributed Wrapper\n",
    "inputData=Input(shape=(None, 244, 244, 3))\n",
    "model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 244, 244, 3))\n",
    "#for layer in model.layers[:278]: #until mixed9_0, untrainable\n",
    "#   layer.trainable = False\n",
    "layer_name = 'mixed3'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "for layer in intermediate_layer_model.layers: #until mixed9_0, untrainable\n",
    "  layer.trainable = False\n",
    "encoded_frame = TimeDistributed(intermediate_layer_model)(inputData)\n",
    "\n",
    "encoded_frame = TimeDistributed(Flatten())(encoded_frame)\n",
    "encoded_frame = TimeDistributed(Dense(64))(encoded_frame)\n",
    "encoded_frame = BatchNormalization()(encoded_frame)\n",
    "encoded_frame = TimeDistributed(LeakyReLU(alpha=0.1))(encoded_frame)\n",
    "intermediateOut = CuDNNLSTM(128, return_sequences = True)(encoded_frame)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "# intermediateOut = CuDNNLSTM(64)(intermediateOut)\n",
    "# intermediateOut = BatchNormalization()(intermediateOut)\n",
    "\n",
    "intermediateOut = TimeDistributed(Dense(32))(intermediateOut)\n",
    "intermediateOut = TimeDistributed(BatchNormalization())(intermediateOut)\n",
    "intermediateOut = TimeDistributed(LeakyReLU(alpha=0.1))(intermediateOut)\n",
    "intermediateOut = TimeDistributed(Dropout(0.4))(intermediateOut)\n",
    "\n",
    "# intermediateOut = Dense(32)(intermediateOut)\n",
    "# intermediateOut = BatchNormalization()(intermediateOut)\n",
    "# intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "\n",
    "intermediateOut = TimeDistributed(Dropout(0.4))(intermediateOut)\n",
    "prediction = TimeDistributed(Dense(29, activation='softmax'))(intermediateOut)\n",
    "optmr = keras.optimizers.adam(lr=0.005, decay = 5e-4)\n",
    "model_final = Model(input = [inputData], output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 244, 244, 3) 0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 13, 13, 768) 2146976   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 129792)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 64)          8306752   \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, None, 128)         99328     \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, None, 32)          4128      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, None, 32)          128       \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 29)          957       \n",
      "=================================================================\n",
      "Total params: 10,559,037\n",
      "Trainable params: 8,411,613\n",
      "Non-trainable params: 2,147,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "399/399 [==============================] - 136s 341ms/step - loss: 2.8297 - acc: 0.1941 - val_loss: 3.2185 - val_acc: 0.0000e+00\n",
      "Epoch 2/15\n",
      "398/399 [============================>.] - ETA: 0s - loss: 2.7928 - acc: 0.2019- ETA: 6s - loss: 2.Epoch 2/15\n",
      "399/399 [==============================] - 145s 364ms/step - loss: 2.7942 - acc: 0.2014 - val_loss: 3.2793 - val_acc: 3.6550e-04\n",
      "Epoch 3/15\n",
      "399/399 [==============================] - 147s 368ms/step - loss: 2.7749 - acc: 0.2043 - val_loss: 3.2404 - val_acc: 0.0000e+00\n",
      "Epoch 4/15\n",
      "157/399 [==========>...................] - ETA: 1:23 - loss: 2.7328 - acc: 0.2200"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    model_final.fit_generator(generator=trainingGen,\n",
    "                    validation_data=validGen,\n",
    "                    use_multiprocessing=True,\n",
    "                    epochs = 15,\n",
    "                    workers=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TimeDistributed Wrapper and freeze all CNN layer to mix8\n",
    "inputData=Input(shape=(None, 244, 244, 3))\n",
    "model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 244, 244, 3))\n",
    "for layer in model.layers: #fix all param and get output from mixed8\n",
    "   layer.trainable = False\n",
    "layer_name = 'mixed8'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "for layer in intermediate_layer_model.layers: #fix all param and get output from mixed8\n",
    "   layer.trainable = False\n",
    "encoded_frame = TimeDistributed(intermediate_layer_model)(inputData)\n",
    "\n",
    "encoded_frame=TimeDistributed(Flatten())(encoded_frame)\n",
    "intermediateOut = CuDNNLSTM(128, return_sequences = True)(encoded_frame)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = CuDNNLSTM(64)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "\n",
    "intermediateOut = Dense(64)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "\n",
    "intermediateOut = Dense(32)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "\n",
    "intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "prediction = Dense(29, activation='softmax')(intermediateOut)\n",
    "optmr_freeze = keras.optimizers.adam(lr=0.01, decay = 5e-4)\n",
    "model_final_freeze = Model(input = [inputData], output = prediction)\n",
    "model_final_freeze.compile(loss = \"categorical_crossentropy\", optimizer = optmr_freeze, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    model_final_freeze.fit_generator(generator=trainingGen,\n",
    "                    validation_data=validGen,\n",
    "                    use_multiprocessing=True,\n",
    "                    epochs = 20,\n",
    "                    workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_final.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_final = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_final.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Testing Set:  0.3709677419354839\n"
     ]
    }
   ],
   "source": [
    "#manually test model using testset\n",
    "testGen=imgDataGenerator(testPath)\n",
    "correct=0\n",
    "with tf.device('GPU:0'):\n",
    "    for i in range(124):\n",
    "        x,y=testGen.__getitem__(i)\n",
    "        pred=model_final.predict(x)\n",
    "        pred=pred.reshape((len(pred[0]),29))\n",
    "        spred=np.sum(pred,axis=0)\n",
    "        aspred=np.argsort(-spred)\n",
    "#         print(aspred[:3])\n",
    "#         print(aspred)\n",
    "#         print(np.argmax(spred))\n",
    "#         print(spred)\n",
    "#         print(np.argmax(y[0][0]))\n",
    "#         print('**')\n",
    "        if(np.argmax(y[0][0]) in aspred[:3]):\n",
    "            correct+=1\n",
    "print('Accuracy of Testing Set: ',correct/124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "a=np.array(a)\n",
    "b=[4,5,6]\n",
    "b=np.array(b)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=np.array([[1,2,3],[3,4,5]])\n",
    "np.sum(c,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
