{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../Preprocessing')\n",
    "from imgDataGenerator import *\n",
    "from preprocessing import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Reshape, Permute, TimeDistributed, CuDNNLSTM,LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/livelab/Desktop/NewResizedBalancedCombo10000/Training/' # directory containing subsets of data with labels\n",
    "valid_path = '/home/livelab/Desktop/NewResizedCombo/Validation/'\n",
    "test_path = '/home/livelab/Desktop/NewResizedCombo/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLayerNumByName(model, name):\n",
    "    layerList=model.layers\n",
    "    return layerList.index(model.get_layer(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 249139 images belonging to 23 classes.\n",
      "Found 163247 images belonging to 23 classes.\n",
      "Found 171954 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 30 # number of epochs to run\n",
    "LEARN_RATE = 0.01 # how much the guesses adjust for loss each time to find the minimum\n",
    "BATCH_SIZE = 64 # how many to process at once (greatest power of 2 that can ft in RAM)\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(zca_whitening=True, zca_epsilon=1e-06,rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, \n",
    "                                                             shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', \n",
    "                                                             cval=0.0, horizontal_flip=True, vertical_flip=True)\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Use the ImageDataGenerators to load the training data\n",
    "train_gen = train_datagen.flow_from_directory(directory=train_path,\n",
    "                                    target_size=(256,256), # size to resize images to\n",
    "                                    color_mode='rgb', # color mode of the images\n",
    "                                    batch_size=BATCH_SIZE, # how many images to process at once\n",
    "                                    class_mode='categorical', # classify into categorical classes\n",
    "                                    shuffle=True # shuffle order of images\n",
    ")\n",
    "valid_gen = valid_datagen.flow_from_directory(directory=valid_path,\n",
    "                                    target_size=(256,256),\n",
    "                                    color_mode='rgb',\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=True\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(directory=test_path,\n",
    "                                    target_size=(256,256),\n",
    "                                    color_mode='rgb',\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "testPath='/home/livelab/Desktop/NewResizedCombo/MajorTest'\n",
    "testGen=imgDataGenerator(testPath, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=testGen.__getitem__(1030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 256, 256, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see label-encoding correspondence\n",
    "train_gen.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/livelab/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/livelab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#full inception\n",
    "#freeze mix3 and prior\n",
    "inputData=Input(shape=(256, 256, 3))\n",
    "model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 256, 256, 3))\n",
    "# layer_name = 'mixed6'\n",
    "# index=findLayerNumByName(model, layer_name)\n",
    "# intermediate_model=Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer(layer_name).output)\n",
    "# for layer in intermediate_model.layers:\n",
    "#     layer.trainable = False\n",
    "intermediateOut = Flatten()(model.output)\n",
    "intermediateOut = Dense(32)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "prediction = Dense(23, activation='softmax')(intermediateOut)\n",
    "optmr = Adam(lr=0.0005, decay = 5e-4)\n",
    "model_final = Model(input = model.input, output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model-full-10000-5x-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size/30\n",
    "STEP_SIZE_VALID=valid_gen.n//valid_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/livelab/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/livelab/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:735: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/129 [==============================] - 428s 3s/step - loss: 2.1914 - acc: 0.3992 - val_loss: 2.2857 - val_acc: 0.3940\n",
      "\n",
      "Epoch 00001: saving model to model-full-10000-5x-01-0.39.hdf5\n",
      "Epoch 2/30\n",
      "130/129 [==============================] - 419s 3s/step - loss: 1.3992 - acc: 0.6411 - val_loss: 2.6632 - val_acc: 0.2011\n",
      "\n",
      "Epoch 00002: saving model to model-full-10000-5x-02-0.20.hdf5\n",
      "Epoch 3/30\n",
      "130/129 [==============================] - 418s 3s/step - loss: 1.1320 - acc: 0.7070 - val_loss: 3.1147 - val_acc: 0.1372\n",
      "\n",
      "Epoch 00003: saving model to model-full-10000-5x-03-0.14.hdf5\n",
      "Epoch 4/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.9676 - acc: 0.7468 - val_loss: 3.1421 - val_acc: 0.2061\n",
      "\n",
      "Epoch 00004: saving model to model-full-10000-5x-04-0.21.hdf5\n",
      "Epoch 5/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.8225 - acc: 0.7863 - val_loss: 2.5083 - val_acc: 0.2462\n",
      "\n",
      "Epoch 00005: saving model to model-full-10000-5x-05-0.25.hdf5\n",
      "Epoch 6/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.7148 - acc: 0.8151 - val_loss: 2.5992 - val_acc: 0.2183\n",
      "\n",
      "Epoch 00006: saving model to model-full-10000-5x-06-0.22.hdf5\n",
      "Epoch 7/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.6775 - acc: 0.8181 - val_loss: 1.9003 - val_acc: 0.4472\n",
      "\n",
      "Epoch 00007: saving model to model-full-10000-5x-07-0.45.hdf5\n",
      "Epoch 8/30\n",
      "130/129 [==============================] - 418s 3s/step - loss: 0.6010 - acc: 0.8458 - val_loss: 2.6851 - val_acc: 0.1680\n",
      "\n",
      "Epoch 00008: saving model to model-full-10000-5x-08-0.17.hdf5\n",
      "Epoch 9/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.5588 - acc: 0.8483 - val_loss: 1.8756 - val_acc: 0.3689\n",
      "\n",
      "Epoch 00009: saving model to model-full-10000-5x-09-0.37.hdf5\n",
      "Epoch 10/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.5389 - acc: 0.8571 - val_loss: 2.7179 - val_acc: 0.2584\n",
      "\n",
      "Epoch 00010: saving model to model-full-10000-5x-10-0.26.hdf5\n",
      "Epoch 11/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.4761 - acc: 0.8733 - val_loss: 3.2949 - val_acc: 0.1230\n",
      "\n",
      "Epoch 00011: saving model to model-full-10000-5x-11-0.12.hdf5\n",
      "Epoch 12/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.4679 - acc: 0.8732 - val_loss: 1.8244 - val_acc: 0.4490\n",
      "\n",
      "Epoch 00012: saving model to model-full-10000-5x-12-0.45.hdf5\n",
      "Epoch 13/30\n",
      "130/129 [==============================] - 418s 3s/step - loss: 0.4043 - acc: 0.8946 - val_loss: 2.1560 - val_acc: 0.2815\n",
      "\n",
      "Epoch 00013: saving model to model-full-10000-5x-13-0.28.hdf5\n",
      "Epoch 14/30\n",
      "130/129 [==============================] - 418s 3s/step - loss: 0.4075 - acc: 0.8886 - val_loss: 2.2957 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00014: saving model to model-full-10000-5x-14-0.43.hdf5\n",
      "Epoch 15/30\n",
      "130/129 [==============================] - 419s 3s/step - loss: 0.3967 - acc: 0.8948 - val_loss: 1.7895 - val_acc: 0.4449\n",
      "\n",
      "Epoch 00015: saving model to model-full-10000-5x-15-0.44.hdf5\n",
      "Epoch 16/30\n",
      "130/129 [==============================] - 421s 3s/step - loss: 0.3815 - acc: 0.8946 - val_loss: 2.4856 - val_acc: 0.3467\n",
      "\n",
      "Epoch 00016: saving model to model-full-10000-5x-16-0.35.hdf5\n",
      "Epoch 17/30\n",
      "130/129 [==============================] - 420s 3s/step - loss: 0.3501 - acc: 0.9026 - val_loss: 2.6068 - val_acc: 0.3075\n",
      "\n",
      "Epoch 00017: saving model to model-full-10000-5x-17-0.31.hdf5\n",
      "Epoch 18/30\n",
      "130/129 [==============================] - 420s 3s/step - loss: 0.3443 - acc: 0.9046 - val_loss: 1.7804 - val_acc: 0.4586\n",
      "\n",
      "Epoch 00018: saving model to model-full-10000-5x-18-0.46.hdf5\n",
      "Epoch 19/30\n",
      "130/129 [==============================] - 424s 3s/step - loss: 0.3318 - acc: 0.9087 - val_loss: 2.1129 - val_acc: 0.3762\n",
      "\n",
      "Epoch 00019: saving model to model-full-10000-5x-19-0.38.hdf5\n",
      "Epoch 20/30\n",
      "130/129 [==============================] - 421s 3s/step - loss: 0.3222 - acc: 0.9137 - val_loss: 1.7953 - val_acc: 0.4922\n",
      "\n",
      "Epoch 00020: saving model to model-full-10000-5x-20-0.49.hdf5\n",
      "Epoch 21/30\n",
      "130/129 [==============================] - 423s 3s/step - loss: 0.2969 - acc: 0.9191 - val_loss: 1.7393 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00021: saving model to model-full-10000-5x-21-0.51.hdf5\n",
      "Epoch 22/30\n",
      "130/129 [==============================] - 420s 3s/step - loss: 0.2828 - acc: 0.9239 - val_loss: 3.0412 - val_acc: 0.2297\n",
      "\n",
      "Epoch 00022: saving model to model-full-10000-5x-22-0.23.hdf5\n",
      "Epoch 23/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2896 - acc: 0.9237 - val_loss: 2.4836 - val_acc: 0.3399\n",
      "\n",
      "Epoch 00023: saving model to model-full-10000-5x-23-0.34.hdf5\n",
      "Epoch 24/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2999 - acc: 0.9144 - val_loss: 2.3754 - val_acc: 0.4056\n",
      "\n",
      "Epoch 00024: saving model to model-full-10000-5x-24-0.41.hdf5\n",
      "Epoch 25/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2711 - acc: 0.9249 - val_loss: 3.0682 - val_acc: 0.2369\n",
      "\n",
      "Epoch 00025: saving model to model-full-10000-5x-25-0.24.hdf5\n",
      "Epoch 26/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2617 - acc: 0.9287 - val_loss: 1.9972 - val_acc: 0.4111\n",
      "\n",
      "Epoch 00026: saving model to model-full-10000-5x-26-0.41.hdf5\n",
      "Epoch 27/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2480 - acc: 0.9334 - val_loss: 2.2480 - val_acc: 0.3994\n",
      "\n",
      "Epoch 00027: saving model to model-full-10000-5x-27-0.40.hdf5\n",
      "Epoch 28/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2366 - acc: 0.9320 - val_loss: 1.8168 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00028: saving model to model-full-10000-5x-28-0.50.hdf5\n",
      "Epoch 29/30\n",
      "130/129 [==============================] - 417s 3s/step - loss: 0.2194 - acc: 0.9428 - val_loss: 2.4989 - val_acc: 0.3706\n",
      "\n",
      "Epoch 00029: saving model to model-full-10000-5x-29-0.37.hdf5\n",
      "Epoch 30/30\n",
      "130/129 [==============================] - 418s 3s/step - loss: 0.2249 - acc: 0.9377 - val_loss: 2.1281 - val_acc: 0.4336\n",
      "\n",
      "Epoch 00030: saving model to model-full-10000-5x-30-0.43.hdf5\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model_final.fit_generator(generator=train_gen,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN, # number of steps in each epoch\n",
    "                        validation_data=valid_gen,\n",
    "                        validation_steps=STEP_SIZE_VALID,\n",
    "                        callbacks=callbacks_list,\n",
    "                        epochs=EPOCH_NUM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(\"model-full-10000-5x-21-0.51.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.631974823157111\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
    "# evaluate the function using the test set\n",
    "test_loss, test_acc = model_final.evaluate_generator(test_gen,\n",
    "                                            STEP_SIZE_TEST)\n",
    "\n",
    "# print test accuracy\n",
    "print('Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =test_gen.__getitem__(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh=model_final.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y2 in yh:\n",
    "    print(np.argmax(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=np.zeros((24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  0  in  2686\n",
      "step  50  in  2686\n",
      "step  100  in  2686\n",
      "step  150  in  2686\n",
      "step  200  in  2686\n",
      "step  250  in  2686\n",
      "step  300  in  2686\n",
      "step  350  in  2686\n",
      "step  400  in  2686\n",
      "step  450  in  2686\n",
      "step  500  in  2686\n",
      "step  550  in  2686\n",
      "step  600  in  2686\n",
      "step  650  in  2686\n",
      "step  700  in  2686\n",
      "step  750  in  2686\n",
      "step  800  in  2686\n",
      "step  850  in  2686\n",
      "step  900  in  2686\n",
      "step  950  in  2686\n",
      "step  1000  in  2686\n",
      "step  1050  in  2686\n",
      "step  1100  in  2686\n",
      "step  1150  in  2686\n",
      "step  1200  in  2686\n",
      "step  1250  in  2686\n",
      "step  1300  in  2686\n",
      "step  1350  in  2686\n",
      "step  1400  in  2686\n",
      "step  1450  in  2686\n",
      "step  1500  in  2686\n",
      "step  1550  in  2686\n",
      "step  1600  in  2686\n",
      "step  1650  in  2686\n",
      "step  1700  in  2686\n",
      "step  1750  in  2686\n",
      "step  1800  in  2686\n",
      "step  1850  in  2686\n",
      "step  1900  in  2686\n",
      "step  1950  in  2686\n",
      "step  2000  in  2686\n",
      "step  2050  in  2686\n",
      "step  2100  in  2686\n",
      "step  2150  in  2686\n",
      "step  2200  in  2686\n",
      "step  2250  in  2686\n",
      "step  2300  in  2686\n",
      "step  2350  in  2686\n",
      "step  2400  in  2686\n",
      "step  2450  in  2686\n",
      "step  2500  in  2686\n",
      "step  2550  in  2686\n",
      "step  2600  in  2686\n",
      "step  2650  in  2686\n"
     ]
    }
   ],
   "source": [
    "#compute confusion matrix\n",
    "#col : truth, #row : pred\n",
    "conf=np.zeros((23,23))\n",
    "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
    "for step in range(STEP_SIZE_TEST):\n",
    "    if(step%50==0):\n",
    "        print('step ', step, ' in ',  STEP_SIZE_TEST)\n",
    "    x,y = test_gen.__getitem__(step)\n",
    "    yh=model_final.predict(x)\n",
    "    for index in range(len(y)):\n",
    "        conf[np.argmax(y[index])][np.argmax(yh[index])]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"model_full23_confision_10K_0.63.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,y=test_gen.__getitem__(500)\n",
    "np.argmax(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  0  in  1048\n",
      "step  50  in  1048\n",
      "step  100  in  1048\n",
      "step  150  in  1048\n",
      "step  200  in  1048\n",
      "step  250  in  1048\n",
      "step  300  in  1048\n",
      "step  350  in  1048\n",
      "step  400  in  1048\n",
      "step  450  in  1048\n",
      "step  500  in  1048\n",
      "step  550  in  1048\n",
      "step  600  in  1048\n",
      "step  650  in  1048\n",
      "step  700  in  1048\n",
      "step  750  in  1048\n",
      "step  800  in  1048\n",
      "step  850  in  1048\n",
      "step  900  in  1048\n",
      "step  950  in  1048\n",
      "step  1000  in  1048\n"
     ]
    }
   ],
   "source": [
    "#compute confusion matrix for majority vote\n",
    "#col : truth, #row : pred\n",
    "conf=np.zeros((23,23))\n",
    "STEP_SIZE_TEST=len(testGen.labels)//testGen.batch_size\n",
    "for step in range(STEP_SIZE_TEST):\n",
    "    if(step%50==0):\n",
    "        print('step ', step, ' in ',  STEP_SIZE_TEST)\n",
    "    x,y = testGen.__getitem__(step)\n",
    "    \n",
    "    yh=model_final.predict(x[0])\n",
    "    major=np.zeros(23)\n",
    "    for eachYh in yh:\n",
    "        major=major+eachYh\n",
    "    conf[np.argmax(y)][np.argmax(major)]+=1\n",
    "#     for index in range(len(y)):\n",
    "#         conf[np.argmax(y[index])][np.argmax(yh[index])]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"model_full23_major_10k_0.63.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testGen.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
