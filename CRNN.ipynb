{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, './Preprocessing')\n",
    "import numpy as np\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from imgDataGenerator import *\n",
    "from preprocessing import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Reshape, Permute, TimeDistributed, CuDNNLSTM,LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam\n",
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Check on Folder Succeed\n"
     ]
    }
   ],
   "source": [
    "#Note for Test, Training, and Validation folders, they all need to have same categories\n",
    "parentPath='/home/livelab/Desktop/NewResizedBinned'\n",
    "checkAndGeneratePath(parentPath)\n",
    "testPath='/home/livelab/Desktop/NewResizedBinned/Test'\n",
    "trainPath='/home/livelab/Desktop/NewResizedBinned/Training'\n",
    "validPath='/home/livelab/Desktop/NewResizedBinned/Validation'\n",
    "\n",
    "trainingGen=imgDataGenerator(trainPath)\n",
    "validGen=imgDataGenerator(validPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPath='/home/billy/Desktop/VideoClasBinned/Test'\n",
    "trainPath='/home/billy/Desktop/VideoClasBinned/Training'\n",
    "validPath='/home/billy/Desktop/VideoClasBinned/Validation'\n",
    "combo=prepdata(trainPath)\n",
    "len(combo)\n",
    "a,b=zip(*combo)\n",
    "b=np.argmax(a,axis=1)\n",
    "b=b.tolist()\n",
    "for i in range(24):\n",
    "    print(b.count(i),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCNN(weightFile):\n",
    "    \"\"\"\n",
    "    Load pretrained CNN and lock all features\n",
    "    \"\"\"\n",
    "    #full inception\n",
    "#freeze mix3 and prior\n",
    "    inputData=Input(shape=(256, 256, 3))\n",
    "    model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 256, 256, 3))\n",
    "    intermediateOut = Flatten()(model.output)\n",
    "    intermediateOut = Dense(32)(intermediateOut)\n",
    "    intermediateOut = BatchNormalization()(intermediateOut)\n",
    "    intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "    intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "    prediction = Dense(24, activation='softmax')(intermediateOut)\n",
    "    optmr = Adam(lr=0.0001, decay = 5e-4)\n",
    "    model_final = Model(input = model.input, output = prediction)\n",
    "    model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])\n",
    "    model_final.load_weights(weightFile)\n",
    "    #retrieve output of second to last layer\n",
    "    lenOfModel=len(model_final.layers)\n",
    "    intermediate_layer_model = Model(inputs=model_final.input,\n",
    "                               outputs=model_final.layers[lenOfModel-2].output)\n",
    "    for layer in intermediate_layer_model.layers: #until mixed9_0, untrainable\n",
    "        layer.trainable = False\n",
    "    return intermediate_layer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLayerNumByName(model, name):\n",
    "    layerList=model.layers\n",
    "    return layerList.index(model.get_layer(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=loadCNN('/home/livelab/Desktop/CELA-VideoClassification/CNN/model-full-10k-0.54.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TimeDistributed Wrapper\n",
    "inputData=Input(shape=(None, 256, 256, 3))\n",
    "model=loadCNN('/home/livelab/Desktop/CELA-VideoClassification/CNN/model-full-10k-0.54.hdf5')\n",
    "encoded_frame = TimeDistributed(model)(inputData)\n",
    "\n",
    "intermediateOut = CuDNNLSTM(1024, return_sequences = False)(encoded_frame)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "# intermediateOut = Dense(128)(intermediateOut)\n",
    "# intermediateOut = BatchNormalization()(intermediateOut)\n",
    "# intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "# intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "prediction = Dense(24, activation='softmax')(intermediateOut)\n",
    "optmr = keras.optimizers.adam(lr=0.005, decay = 5e-4)\n",
    "model_final = Model(input = [inputData], output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])\n",
    "filepath = \"CRNN-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, None, 256, 256, 3) 0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, None, 32)          24162240  \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_7 (CuDNNLSTM)     (None, 1024)              4333568   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1051 (Ba (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 24)                24600     \n",
      "=================================================================\n",
      "Total params: 28,524,504\n",
      "Trainable params: 4,360,216\n",
      "Non-trainable params: 24,164,288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=trainingGen.__len__()//trainingGen.batch_size/5\n",
    "STEP_SIZE_VAL=validGen.__len__()//validGen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1678/1678 [==============================] - 266s 159ms/step - loss: 2.9797 - acc: 0.1544 - val_loss: 11.1260 - val_acc: 0.0775\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.07746, saving model to CRNN-01-0.08.hdf5\n",
      "Epoch 2/40\n",
      "1678/1678 [==============================] - 217s 129ms/step - loss: 2.9321 - acc: 0.1633 - val_loss: 10.4367 - val_acc: 0.0467\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.07746\n",
      "Epoch 3/40\n",
      "1678/1678 [==============================] - 219s 131ms/step - loss: 2.9374 - acc: 0.1704 - val_loss: 11.1295 - val_acc: 0.0209\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.07746\n",
      "Epoch 4/40\n",
      "1677/1678 [============================>.] - ETA: 0s - loss: 2.9591 - acc: 0.1676"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    model_final.fit_generator(generator=trainingGen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validGen,\n",
    "                    validation_steps=STEP_SIZE_VAL,\n",
    "                    callbacks=callbacks_list,\n",
    "                    use_multiprocessing=True,\n",
    "                    epochs = 40,\n",
    "                    workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_final.to_json()\n",
    "with open(\"modelmix3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final.save_weights(\"modelmix3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('saved-model-07-0.16.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_final = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_final.load_weights(\"saved-model-07-0.16.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(\"saved-model-2-01-0.17.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually test model using testset\n",
    "testGen=imgDataGenerator(testPath)\n",
    "correct=0\n",
    "laxcorrect=0\n",
    "with tf.device('GPU:0'):\n",
    "    for i in range(193):\n",
    "        x,y=testGen.__getitem__(i)\n",
    "        pred=model_final.predict(x)\n",
    "        pred=pred.reshape((len(pred[0]),24))\n",
    "        spred=np.sum(pred,axis=0)\n",
    "        aspred=np.argsort(-spred)\n",
    "#         print(aspred[:3])\n",
    "#         print(aspred)\n",
    "#         print(np.argmax(spred))\n",
    "#         print(spred)\n",
    "#         print(np.argmax(y[0][0]))\n",
    "#         print('**')\n",
    "        if(np.argmax(y[0][0]) in aspred[:1]):\n",
    "            correct+=1\n",
    "        if(np.argmax(y[0][0]) in aspred[:3]):\n",
    "            laxcorrect+=1    \n",
    "print('Accuracy of Testing Set: ',correct/193, laxcorrect/193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4444167e-02 5.1272457e-04 3.3864358e-03 1.3929498e-02 8.7655790e-04\n",
      " 3.9349613e-04 2.0848449e-04 2.9556248e-03 2.6248468e-03 2.7816342e-02\n",
      " 2.7376935e-03 1.1535666e-02 1.9808723e-04 3.3293080e-03 3.6888491e-02\n",
      " 7.2536373e-01 7.9956785e-04 1.6302963e-03 4.3726549e-03 1.0733723e-03\n",
      " 3.4537264e-03 1.2404115e-01 6.8205590e-03 6.0759677e-04]\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "14\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Accuracy of Testing Set:  0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "#manually test model using testset\n",
    "testGen=imgDataGenerator(testPath)\n",
    "correct=0\n",
    "laxcorrect=0\n",
    "with tf.device('GPU:0'):\n",
    "    x,y=testGen.__getitem__(0)\n",
    "    pred=model_final.predict(x)\n",
    "    pred=pred.reshape((len(pred[0]),24))\n",
    "    print(pred[0])\n",
    "    for p in pred:\n",
    "        print(np.argmax(p))\n",
    "    print(np.argmax(y))\n",
    "    print(y)\n",
    "print('Accuracy of Testing Set: ',correct/193, laxcorrect/193)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testGen=imgDataGenerator(testPath)\n",
    "combo=prepdata(testPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=zip(*combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2,3,4,5]\n",
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
