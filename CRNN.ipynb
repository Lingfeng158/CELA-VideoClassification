{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, './Preprocessing')\n",
    "import numpy as np\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "from imgDataGenerator import *\n",
    "from preprocessing import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Reshape, Permute, TimeDistributed, CuDNNLSTM,LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.layers.merge import concatenate\n",
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data dimension will be: #bag * #frame * 244 * 244 * 3\n",
    "#simple implementation of CNN>LSTM without multires\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note for Test, Training, and Validation folders, they all need to have same categories\n",
    "parentPath='/home/billy/Desktop/NewResizedBinned'\n",
    "checkAndGeneratePath(parentPath)\n",
    "testPath='/home/billy/Desktop/NewResizedBinned/Test'\n",
    "trainPath='/home/billy/Desktop/NewResizedBinned/Training'\n",
    "validPath='/home/billy/Desktop/NewResizedBinned/Validation'\n",
    "\n",
    "trainingGen=imgDataGenerator(trainPath)\n",
    "validGen=imgDataGenerator(validPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testPath='/home/billy/Desktop/VideoClasBinned/Test'\n",
    "trainPath='/home/billy/Desktop/VideoClasBinned/Training'\n",
    "validPath='/home/billy/Desktop/VideoClasBinned/Validation'\n",
    "combo=prepdata(trainPath)\n",
    "len(combo)\n",
    "a,b=zip(*combo)\n",
    "b=np.argmax(a,axis=1)\n",
    "b=b.tolist()\n",
    "for i in range(24):\n",
    "    print(b.count(i),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TimeDistributed Wrapper\n",
    "inputData=Input(shape=(None, 256, 256, 3))\n",
    "model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 256, 256, 3))\n",
    "#for layer in model.layers[:278]: #until mixed9_0, untrainable\n",
    "#   layer.trainable = False\n",
    "layer_name = 'mixed9'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "# for layer in intermediate_layer_model.layers: #until mixed9_0, untrainable\n",
    "#   layer.trainable = False\n",
    "encoded_frame = TimeDistributed(intermediate_layer_model)(inputData)\n",
    "\n",
    "encoded_frame = TimeDistributed(Flatten())(encoded_frame)\n",
    "# encoded_frame = TimeDistributed(Dense(64))(encoded_frame)\n",
    "# encoded_frame = BatchNormalization()(encoded_frame)\n",
    "# encoded_frame = TimeDistributed(LeakyReLU(alpha=0.1))(encoded_frame)\n",
    "intermediateOut = CuDNNLSTM(128, return_sequences = True)(encoded_frame)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = CuDNNLSTM(64, return_sequences = True)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "\n",
    "intermediateOut = TimeDistributed(Dense(32))(intermediateOut)\n",
    "intermediateOut = TimeDistributed(BatchNormalization())(intermediateOut)\n",
    "intermediateOut = TimeDistributed(LeakyReLU(alpha=0.1))(intermediateOut)\n",
    "intermediateOut = TimeDistributed(Dropout(0.4))(intermediateOut)\n",
    "\n",
    "# intermediateOut = Dense(32)(intermediateOut)\n",
    "# intermediateOut = BatchNormalization()(intermediateOut)\n",
    "# intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "\n",
    "intermediateOut = TimeDistributed(Dropout(0.4))(intermediateOut)\n",
    "prediction = TimeDistributed(Dense(24, activation='softmax'))(intermediateOut)\n",
    "optmr = keras.optimizers.adam(lr=0.01, decay = 5e-4)\n",
    "model_final = Model(input = [inputData], output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    model_final.fit_generator(generator=trainingGen,\n",
    "                    validation_data=validGen,\n",
    "                    use_multiprocessing=True,\n",
    "                    epochs = 5,\n",
    "                    workers=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TimeDistributed Wrapper and freeze all CNN layer to mix8\n",
    "inputData=Input(shape=( 256, 256, 3))\n",
    "inputDataTime=Input(shape=(None, 256, 256, 3))\n",
    "tower_1 = Conv2D(8, (1,1), padding='same')(inputData)\n",
    "tower_1 = LeakyReLU(alpha=0.1)(tower_1)\n",
    "tower_1 = Conv2D(8, (3,3), padding='same')(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.1)(tower_1)\n",
    "tower_1 = MaxPooling2D()(tower_1)\n",
    "tower_2 = Conv2D(8, (1,1), padding='same')(inputData)\n",
    "tower_2 = LeakyReLU(alpha=0.1)(tower_2)\n",
    "tower_2 = Conv2D(8, (5,5), padding='same')(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.1)(tower_2)\n",
    "tower_2 = MaxPooling2D()(tower_2)\n",
    "tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(inputData)\n",
    "tower_3 = Conv2D(8, (1,1), padding='same')(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.1)(tower_3)\n",
    "tower_3 = MaxPooling2D()(tower_3)\n",
    "mix0 = concatenate([tower_1, tower_2, tower_3], axis = 3)\n",
    "tower_4 = Conv2D(16, (1,1), padding='same')(mix0)\n",
    "tower_4 = LeakyReLU(alpha=0.1)(tower_4)\n",
    "tower_4 = Conv2D(16, (3,3), padding='same')(tower_4)\n",
    "tower_4 = LeakyReLU(alpha=0.1)(tower_4)\n",
    "tower_4 = MaxPooling2D()(tower_4)\n",
    "tower_5 = Conv2D(16, (1,1), padding='same')(mix0)\n",
    "tower_5 = LeakyReLU(alpha=0.1)(tower_5)\n",
    "tower_5 = Conv2D(16, (5,5), padding='same')(tower_5)\n",
    "tower_5 = LeakyReLU(alpha=0.1)(tower_5)\n",
    "tower_5 = MaxPooling2D()(tower_5)\n",
    "tower_6 = MaxPooling2D((3,3), strides=(1,1), padding='same')(mix0)\n",
    "tower_6 = Conv2D(16, (1,1), padding='same')(tower_6)\n",
    "tower_6 = LeakyReLU(alpha=0.1)(tower_6)\n",
    "tower_6 = MaxPooling2D()(tower_6)                 \n",
    "mix1 = concatenate([tower_4, tower_5, tower_6], axis = 3)\n",
    "intermediate_layer_model = Model(inputs=inputData,\n",
    "                                 outputs=mix1)\n",
    "encoded_frame = TimeDistributed(intermediate_layer_model)(inputDataTime)\n",
    "encoded_frame=TimeDistributed(Flatten())(encoded_frame)\n",
    "intermediateOut = CuDNNLSTM(128, return_sequences = True)(encoded_frame)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = CuDNNLSTM(64, return_sequences = True)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "\n",
    "# intermediateOut = Dense(64)(intermediateOut)\n",
    "# intermediateOut = BatchNormalization()(intermediateOut)\n",
    "# intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "# intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "\n",
    "intermediateOut = TimeDistributed(Dense(32))(intermediateOut)\n",
    "intermediateOut = TimeDistributed(BatchNormalization())(intermediateOut)\n",
    "intermediateOut = TimeDistributed(LeakyReLU(alpha=0.1))(intermediateOut)\n",
    "\n",
    "intermediateOut = TimeDistributed(Dropout(0.4))(intermediateOut)\n",
    "prediction = TimeDistributed(Dense(24, activation='softmax'))(intermediateOut)\n",
    "optmr_freeze = keras.optimizers.adam(lr=0.005, decay = 5e-4)\n",
    "model_final = Model(input = [inputDataTime], output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr_freeze, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    model_final_freeze.fit_generator(generator=trainingGen,\n",
    "                    validation_data=validGen,\n",
    "                    use_multiprocessing=True,\n",
    "                    epochs = 20,\n",
    "                    workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_final.to_json()\n",
    "with open(\"modelmix3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final.save_weights(\"modelmix3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model_final = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model_final.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually test model using testset\n",
    "testGen=imgDataGenerator(testPath)\n",
    "correct=0\n",
    "laxcorrect=0\n",
    "with tf.device('GPU:0'):\n",
    "    for i in range(124):\n",
    "        x,y=testGen.__getitem__(i)\n",
    "        pred=model_final.predict(x)\n",
    "        pred=pred.reshape((len(pred[0]),24))\n",
    "        spred=np.sum(pred,axis=0)\n",
    "        aspred=np.argsort(-spred)\n",
    "#         print(aspred[:3])\n",
    "#         print(aspred)\n",
    "#         print(np.argmax(spred))\n",
    "#         print(spred)\n",
    "#         print(np.argmax(y[0][0]))\n",
    "#         print('**')\n",
    "        if(np.argmax(y[0][0]) in aspred[:2]):\n",
    "            correct+=1\n",
    "        if(np.argmax(y[0][0]) in aspred[:4]):\n",
    "            laxcorrect+=1    \n",
    "print('Accuracy of Testing Set: ',correct/124, laxcorrect/124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
