{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../Preprocessing')\n",
    "from imgDataGenerator import *\n",
    "from preprocessing import *\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, LSTM, Reshape, Permute, TimeDistributed, CuDNNLSTM,LeakyReLU\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/livelab/Desktop/NewResizedBalanced10000/Training/' # directory containing subsets of data with labels\n",
    "valid_path = '/home/livelab/Desktop/NewResized/Validation/'\n",
    "test_path = '/home/livelab/Desktop/NewResized/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLayerNumByName(model, name):\n",
    "    layerList=model.layers\n",
    "    return layerList.index(model.get_layer(layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:336: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260452 images belonging to 24 classes.\n",
      "Found 163247 images belonging to 24 classes.\n",
      "Found 171954 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "EPOCH_NUM = 30 # number of epochs to run\n",
    "LEARN_RATE = 0.01 # how much the guesses adjust for loss each time to find the minimum\n",
    "BATCH_SIZE = 64 # how many to process at once (greatest power of 2 that can ft in RAM)\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(zca_whitening=True, zca_epsilon=1e-06,rotation_range=0, width_shift_range=0.0, height_shift_range=0.0, brightness_range=None, \n",
    "                                                             shear_range=0.0, zoom_range=0.0, channel_shift_range=0.0, fill_mode='nearest', \n",
    "                                                             cval=0.0, horizontal_flip=True, vertical_flip=True)\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "test_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Use the ImageDataGenerators to load the training data\n",
    "train_gen = train_datagen.flow_from_directory(directory=train_path,\n",
    "                                    target_size=(256,256), # size to resize images to\n",
    "                                    color_mode='rgb', # color mode of the images\n",
    "                                    batch_size=BATCH_SIZE, # how many images to process at once\n",
    "                                    class_mode='categorical', # classify into categorical classes\n",
    "                                    shuffle=True # shuffle order of images\n",
    ")\n",
    "valid_gen = valid_datagen.flow_from_directory(directory=valid_path,\n",
    "                                    target_size=(256,256),\n",
    "                                    color_mode='rgb',\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=True\n",
    ")\n",
    "test_gen = test_datagen.flow_from_directory(directory=test_path,\n",
    "                                    target_size=(256,256),\n",
    "                                    color_mode='rgb',\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    class_mode='categorical',\n",
    "                                    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "testPath='/home/livelab/Desktop/NewResizedBinned/Test'\n",
    "testGen=imgDataGenerator(testPath, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=testGen.__getitem__(1030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 256, 256, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see label-encoding correspondence\n",
    "train_gen.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/livelab/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/livelab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/livelab/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#full inception\n",
    "#freeze mix3 and prior\n",
    "inputData=Input(shape=(256, 256, 3))\n",
    "model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False,input_shape = ( 256, 256, 3))\n",
    "# layer_name = 'mixed6'\n",
    "# index=findLayerNumByName(model, layer_name)\n",
    "# intermediate_model=Model(inputs=model.input,\n",
    "#                                  outputs=model.get_layer(layer_name).output)\n",
    "# for layer in intermediate_model.layers:\n",
    "#     layer.trainable = False\n",
    "intermediateOut = Flatten()(model.output)\n",
    "intermediateOut = Dense(32)(intermediateOut)\n",
    "intermediateOut = BatchNormalization()(intermediateOut)\n",
    "intermediateOut = LeakyReLU(alpha=0.1)(intermediateOut)\n",
    "intermediateOut = Dropout(0.4)(intermediateOut)\n",
    "prediction = Dense(24, activation='softmax')(intermediateOut)\n",
    "optmr = Adam(lr=0.0005, decay = 5e-4)\n",
    "model_final = Model(input = model.input, output = prediction)\n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optmr, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"model-full-10000R-5x-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size/20\n",
    "STEP_SIZE_VALID=valid_gen.n//valid_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "204/203 [==============================] - 461s 2s/step - loss: 1.9835 - acc: 0.4514 - val_loss: 2.7316 - val_acc: 0.1709\n",
      "\n",
      "Epoch 00001: saving model to model-full-10000R-5x-01-0.17.hdf5\n",
      "Epoch 2/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 1.2297 - acc: 0.6765 - val_loss: 2.4085 - val_acc: 0.2518\n",
      "\n",
      "Epoch 00002: saving model to model-full-10000R-5x-02-0.25.hdf5\n",
      "Epoch 3/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.9313 - acc: 0.7478 - val_loss: 2.4143 - val_acc: 0.1854\n",
      "\n",
      "Epoch 00003: saving model to model-full-10000R-5x-03-0.19.hdf5\n",
      "Epoch 4/30\n",
      "204/203 [==============================] - 450s 2s/step - loss: 0.7630 - acc: 0.7894 - val_loss: 2.2321 - val_acc: 0.2635\n",
      "\n",
      "Epoch 00004: saving model to model-full-10000R-5x-04-0.26.hdf5\n",
      "Epoch 5/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.6643 - acc: 0.8179 - val_loss: 2.1401 - val_acc: 0.2707\n",
      "\n",
      "Epoch 00005: saving model to model-full-10000R-5x-05-0.27.hdf5\n",
      "Epoch 6/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.5987 - acc: 0.8315 - val_loss: 2.3554 - val_acc: 0.2671\n",
      "\n",
      "Epoch 00006: saving model to model-full-10000R-5x-06-0.27.hdf5\n",
      "Epoch 7/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.5508 - acc: 0.8402 - val_loss: 2.6231 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00007: saving model to model-full-10000R-5x-07-0.19.hdf5\n",
      "Epoch 8/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.4898 - acc: 0.8562 - val_loss: 2.4042 - val_acc: 0.2297\n",
      "\n",
      "Epoch 00008: saving model to model-full-10000R-5x-08-0.23.hdf5\n",
      "Epoch 9/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.4525 - acc: 0.8710 - val_loss: 2.1419 - val_acc: 0.3883\n",
      "\n",
      "Epoch 00009: saving model to model-full-10000R-5x-09-0.39.hdf5\n",
      "Epoch 10/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.4141 - acc: 0.8840 - val_loss: 3.3390 - val_acc: 0.1529\n",
      "\n",
      "Epoch 00010: saving model to model-full-10000R-5x-10-0.15.hdf5\n",
      "Epoch 11/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.3882 - acc: 0.8909 - val_loss: 1.9175 - val_acc: 0.4113\n",
      "\n",
      "Epoch 00011: saving model to model-full-10000R-5x-11-0.41.hdf5\n",
      "Epoch 12/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.3697 - acc: 0.8910 - val_loss: 2.6720 - val_acc: 0.2253\n",
      "\n",
      "Epoch 00012: saving model to model-full-10000R-5x-12-0.23.hdf5\n",
      "Epoch 13/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.3511 - acc: 0.8997 - val_loss: 2.3699 - val_acc: 0.3371\n",
      "\n",
      "Epoch 00013: saving model to model-full-10000R-5x-13-0.34.hdf5\n",
      "Epoch 14/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.3374 - acc: 0.9010 - val_loss: 3.2114 - val_acc: 0.1984\n",
      "\n",
      "Epoch 00014: saving model to model-full-10000R-5x-14-0.20.hdf5\n",
      "Epoch 15/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.3331 - acc: 0.9017 - val_loss: 2.1812 - val_acc: 0.3477\n",
      "\n",
      "Epoch 00015: saving model to model-full-10000R-5x-15-0.35.hdf5\n",
      "Epoch 16/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2983 - acc: 0.9130 - val_loss: 2.2351 - val_acc: 0.3367\n",
      "\n",
      "Epoch 00016: saving model to model-full-10000R-5x-16-0.34.hdf5\n",
      "Epoch 17/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2970 - acc: 0.9125 - val_loss: 2.5357 - val_acc: 0.3496\n",
      "\n",
      "Epoch 00017: saving model to model-full-10000R-5x-17-0.35.hdf5\n",
      "Epoch 18/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2879 - acc: 0.9133 - val_loss: 2.0889 - val_acc: 0.3806\n",
      "\n",
      "Epoch 00018: saving model to model-full-10000R-5x-18-0.38.hdf5\n",
      "Epoch 19/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2700 - acc: 0.9188 - val_loss: 2.3560 - val_acc: 0.3992\n",
      "\n",
      "Epoch 00019: saving model to model-full-10000R-5x-19-0.40.hdf5\n",
      "Epoch 20/30\n",
      "204/203 [==============================] - 450s 2s/step - loss: 0.2751 - acc: 0.9184 - val_loss: 1.8866 - val_acc: 0.4266\n",
      "\n",
      "Epoch 00020: saving model to model-full-10000R-5x-20-0.43.hdf5\n",
      "Epoch 21/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2571 - acc: 0.9236 - val_loss: 2.5641 - val_acc: 0.2865\n",
      "\n",
      "Epoch 00021: saving model to model-full-10000R-5x-21-0.29.hdf5\n",
      "Epoch 22/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2404 - acc: 0.9266 - val_loss: 2.0704 - val_acc: 0.4324\n",
      "\n",
      "Epoch 00022: saving model to model-full-10000R-5x-22-0.43.hdf5\n",
      "Epoch 23/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2320 - acc: 0.9321 - val_loss: 2.7491 - val_acc: 0.3074\n",
      "\n",
      "Epoch 00023: saving model to model-full-10000R-5x-23-0.31.hdf5\n",
      "Epoch 24/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2235 - acc: 0.9332 - val_loss: 2.1804 - val_acc: 0.3256\n",
      "\n",
      "Epoch 00024: saving model to model-full-10000R-5x-24-0.33.hdf5\n",
      "Epoch 25/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2121 - acc: 0.9358 - val_loss: 2.7263 - val_acc: 0.3581\n",
      "\n",
      "Epoch 00025: saving model to model-full-10000R-5x-25-0.36.hdf5\n",
      "Epoch 26/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2097 - acc: 0.9393 - val_loss: 3.7143 - val_acc: 0.1827\n",
      "\n",
      "Epoch 00026: saving model to model-full-10000R-5x-26-0.18.hdf5\n",
      "Epoch 27/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2060 - acc: 0.9377 - val_loss: 3.5720 - val_acc: 0.2265\n",
      "\n",
      "Epoch 00027: saving model to model-full-10000R-5x-27-0.23.hdf5\n",
      "Epoch 28/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.2004 - acc: 0.9370 - val_loss: 1.8672 - val_acc: 0.4809\n",
      "\n",
      "Epoch 00028: saving model to model-full-10000R-5x-28-0.48.hdf5\n",
      "Epoch 29/30\n",
      "204/203 [==============================] - 449s 2s/step - loss: 0.1910 - acc: 0.9436 - val_loss: 2.5896 - val_acc: 0.2973\n",
      "\n",
      "Epoch 00029: saving model to model-full-10000R-5x-29-0.30.hdf5\n",
      "Epoch 30/30\n",
      "204/203 [==============================] - 448s 2s/step - loss: 0.2006 - acc: 0.9416 - val_loss: 3.2198 - val_acc: 0.1946\n",
      "\n",
      "Epoch 00030: saving model to model-full-10000R-5x-30-0.19.hdf5\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model_final.fit_generator(generator=train_gen,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN, # number of steps in each epoch\n",
    "                        validation_data=valid_gen,\n",
    "                        validation_steps=STEP_SIZE_VALID,\n",
    "                        callbacks=callbacks_list,\n",
    "                        epochs=EPOCH_NUM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.load_weights(\"model-full-10000R-5x-28-0.48.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5430996370067014\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
    "# evaluate the function using the test set\n",
    "test_loss, test_acc = model_final.evaluate_generator(test_gen,\n",
    "                                            STEP_SIZE_TEST)\n",
    "\n",
    "# print test accuracy\n",
    "print('Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =test_gen.__getitem__(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh=model_final.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y2 in yh:\n",
    "    print(np.argmax(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y:\n",
    "    print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=np.zeros((24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  0  in  2686\n",
      "step  50  in  2686\n",
      "step  100  in  2686\n",
      "step  150  in  2686\n",
      "step  200  in  2686\n",
      "step  250  in  2686\n",
      "step  300  in  2686\n",
      "step  350  in  2686\n",
      "step  400  in  2686\n",
      "step  450  in  2686\n",
      "step  500  in  2686\n",
      "step  550  in  2686\n",
      "step  600  in  2686\n",
      "step  650  in  2686\n",
      "step  700  in  2686\n",
      "step  750  in  2686\n",
      "step  800  in  2686\n",
      "step  850  in  2686\n",
      "step  900  in  2686\n",
      "step  950  in  2686\n",
      "step  1000  in  2686\n",
      "step  1050  in  2686\n",
      "step  1100  in  2686\n",
      "step  1150  in  2686\n",
      "step  1200  in  2686\n",
      "step  1250  in  2686\n",
      "step  1300  in  2686\n",
      "step  1350  in  2686\n",
      "step  1400  in  2686\n",
      "step  1450  in  2686\n",
      "step  1500  in  2686\n",
      "step  1550  in  2686\n",
      "step  1600  in  2686\n",
      "step  1650  in  2686\n",
      "step  1700  in  2686\n",
      "step  1750  in  2686\n",
      "step  1800  in  2686\n",
      "step  1850  in  2686\n",
      "step  1900  in  2686\n",
      "step  1950  in  2686\n",
      "step  2000  in  2686\n",
      "step  2050  in  2686\n",
      "step  2100  in  2686\n",
      "step  2150  in  2686\n",
      "step  2200  in  2686\n",
      "step  2250  in  2686\n",
      "step  2300  in  2686\n",
      "step  2350  in  2686\n",
      "step  2400  in  2686\n",
      "step  2450  in  2686\n",
      "step  2500  in  2686\n",
      "step  2550  in  2686\n",
      "step  2600  in  2686\n",
      "step  2650  in  2686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.3730e+03, 0.0000e+00, 0.0000e+00, 9.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6600e+02,\n",
       "        0.0000e+00, 3.8300e+02, 0.0000e+00, 4.2200e+02, 8.0600e+02,\n",
       "        5.6500e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 9.4100e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 2.5425e+04, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 7.2200e+02, 4.5910e+03, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.0000e+00, 1.3000e+01, 0.0000e+00],\n",
       "       [1.2100e+02, 0.0000e+00, 2.8900e+02, 7.1200e+02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5000e+02,\n",
       "        0.0000e+00, 1.1770e+03, 0.0000e+00, 0.0000e+00, 8.3000e+01,\n",
       "        1.2000e+01, 0.0000e+00, 0.0000e+00, 4.0000e+01, 0.0000e+00,\n",
       "        4.9780e+03, 2.8000e+01, 4.9000e+02, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7800e+03, 2.2000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.4000e+01,\n",
       "        0.0000e+00, 3.4790e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4000e+01, 0.0000e+00,\n",
       "        2.2400e+02, 5.3000e+01, 4.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.1000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.5160e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1780e+03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6000e+01,\n",
       "        0.0000e+00, 5.6500e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.4120e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.9400e+02, 1.6800e+02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.4500e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 8.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0860e+03, 6.1600e+02, 1.3380e+03, 0.0000e+00,\n",
       "        0.0000e+00, 5.4680e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 7.0000e+00, 5.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.8950e+03, 0.0000e+00, 0.0000e+00, 2.1200e+02, 0.0000e+00,\n",
       "        0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00, 7.6800e+02,\n",
       "        0.0000e+00, 2.0680e+03, 0.0000e+00, 2.0600e+02, 2.8100e+02,\n",
       "        2.9000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00, 8.2200e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0000e+00, 0.0000e+00, 3.0200e+02, 6.3000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2000e+01,\n",
       "        1.4430e+03, 7.1000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9510e+03, 0.0000e+00,\n",
       "        9.4000e+01, 4.8000e+01, 4.0740e+03, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9000e+02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3300e+02,\n",
       "        0.0000e+00, 1.5260e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.6700e+02, 3.3600e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 6.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0150e+03, 0.0000e+00, 0.0000e+00, 3.0000e+00,\n",
       "        0.0000e+00, 1.6000e+01, 4.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.7650e+03, 1.0940e+03, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [2.3830e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3300e+02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8770e+03, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.1400e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [6.3400e+02, 0.0000e+00, 0.0000e+00, 1.8100e+02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8000e+01,\n",
       "        0.0000e+00, 9.0900e+02, 0.0000e+00, 0.0000e+00, 9.5650e+03,\n",
       "        1.6210e+03, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 5.3040e+03, 0.0000e+00, 0.0000e+00],\n",
       "       [4.0500e+02, 0.0000e+00, 0.0000e+00, 4.7000e+01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2000e+01,\n",
       "        0.0000e+00, 9.0000e+01, 0.0000e+00, 0.0000e+00, 9.6700e+02,\n",
       "        7.8100e+02, 0.0000e+00, 0.0000e+00, 4.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 9.3600e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 2.2000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.5000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.4930e+03, 6.7000e+01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 1.8000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.7800e+02, 1.4480e+03, 0.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       [1.0000e+01, 0.0000e+00, 3.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9000e+01,\n",
       "        6.0000e+00, 1.4000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7400e+02, 0.0000e+00,\n",
       "        1.6000e+01, 4.8000e+01, 1.7800e+02, 0.0000e+00],\n",
       "       [4.7000e+01, 0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00,\n",
       "        4.0000e+02, 3.4000e+01, 0.0000e+00, 0.0000e+00, 2.5500e+02,\n",
       "        0.0000e+00, 1.3000e+01, 0.0000e+00, 4.3000e+01, 4.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2950e+03,\n",
       "        0.0000e+00, 8.5900e+02, 0.0000e+00, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7460e+03, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4000e+01,\n",
       "        0.0000e+00, 4.0710e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
       "        2.2380e+03, 5.1000e+01, 5.0000e+00, 0.0000e+00],\n",
       "       [1.1390e+03, 0.0000e+00, 0.0000e+00, 7.2700e+02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3700e+02,\n",
       "        0.0000e+00, 3.2070e+03, 0.0000e+00, 6.4900e+02, 9.9900e+02,\n",
       "        1.0000e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.0000e+00, 3.7550e+03, 0.0000e+00, 0.0000e+00],\n",
       "       [1.1600e+02, 0.0000e+00, 2.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00,\n",
       "        1.5000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3700e+02, 0.0000e+00,\n",
       "        2.0000e+00, 0.0000e+00, 3.6500e+03, 0.0000e+00],\n",
       "       [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4170e+03]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute confusion matrix\n",
    "#col : truth, #row : pred\n",
    "conf=np.zeros((24,24))\n",
    "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
    "for step in range(STEP_SIZE_TEST):\n",
    "    if(step%50==0):\n",
    "        print('step ', step, ' in ',  STEP_SIZE_TEST)\n",
    "    x,y = test_gen.__getitem__(step)\n",
    "    yh=model_final.predict(x)\n",
    "    for index in range(len(y)):\n",
    "        conf[np.argmax(y[index])][np.argmax(yh[index])]+=1\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"model_full_confision_5000_0.50.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,y=test_gen.__getitem__(500)\n",
    "np.argmax(y,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  0  in  1057\n",
      "step  50  in  1057\n",
      "step  100  in  1057\n",
      "step  150  in  1057\n",
      "step  200  in  1057\n",
      "step  250  in  1057\n",
      "step  300  in  1057\n",
      "step  350  in  1057\n",
      "step  400  in  1057\n",
      "step  450  in  1057\n",
      "step  500  in  1057\n",
      "step  550  in  1057\n",
      "step  600  in  1057\n",
      "step  650  in  1057\n",
      "step  700  in  1057\n",
      "step  750  in  1057\n",
      "step  800  in  1057\n",
      "step  850  in  1057\n",
      "step  900  in  1057\n",
      "step  950  in  1057\n",
      "step  1000  in  1057\n",
      "step  1050  in  1057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.,   0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,  11.,   8.,   5.,   0.,   0.,   0.,   0.,   0.,   7.,\n",
       "          0.,   0.],\n",
       "       [  0., 170.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          9.,   0.,   3.,   0.,   0.,   0.,   0.,   1.,   0.,  10.,   2.,\n",
       "         13.,   0.],\n",
       "       [  0.,   0.,   0.,  20.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,\n",
       "          2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  16.,  13.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,  10.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  15.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,  21.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   4.,   1.,   0.,   0.,   0.,\n",
       "          0.,  14.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   7.,  40.,   0.,   0.,   0.,\n",
       "          0.,   5.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  4.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   0.,  11.,   0.,\n",
       "          3.,   0.,   8.,   2.,   0.,   0.,   0.,   0.,   0.,   3.,  11.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  26.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   7.,   0.,   0.,   0.,\n",
       "         18.,   0.],\n",
       "       [  1.,   0.,   0.,   4.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,\n",
       "          4.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,   7.,\n",
       "          0.,   0.],\n",
       "       [  0.,   3.,   0.,   0.,   0.,   0.,   8.,   0.,   0.,   0.,   0.,\n",
       "          0.,  12.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
       "          0.,   0.,  48.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   2.,\n",
       "          0.,   0.],\n",
       "       [  2.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,  57.,  14.,   0.,   0.,   0.,   0.,   6.,  27.,\n",
       "          0.,   0.],\n",
       "       [  1.,   0.,   0.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   4.,   6.,   0.,   0.,   0.,   0.,   2.,   4.,\n",
       "          0.,   0.],\n",
       "       [  0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   3.,   0.,   0.,   0.,  10.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   1.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   7.,   0.,   0.,   0.,   1.,   6.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   6.,   0.,   0.,   0.,\n",
       "          2.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,  39.,   0.,   0.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,  16.,   0.,   0.,   0.,   0.,   0.,   5.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  50.,   0.,\n",
       "          0.,   0.],\n",
       "       [  1.,   0.,   0.,   6.,   0.,   0.,   0.,   0.,   0.,  10.,   0.,\n",
       "          6.,   0.,  11.,   9.,  11.,   0.,   0.,   0.,   0.,   2.,  25.,\n",
       "          0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7.,\n",
       "          0.,   0.,   1.,   0.,   0.,   0.,   0.,  10.,   0.,   0.,   0.,\n",
       "         12.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,  24.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute confusion matrix for majority vote\n",
    "#col : truth, #row : pred\n",
    "conf=np.zeros((24,24))\n",
    "STEP_SIZE_TEST=len(testGen.labels)//testGen.batch_size\n",
    "for step in range(STEP_SIZE_TEST):\n",
    "    if(step%50==0):\n",
    "        print('step ', step, ' in ',  STEP_SIZE_TEST)\n",
    "    x,y = testGen.__getitem__(step)\n",
    "    \n",
    "    yh=model_final.predict(x[0])\n",
    "    major=np.zeros(24)\n",
    "    for eachYh in yh:\n",
    "        major=major+eachYh\n",
    "    conf[np.argmax(y)][np.argmax(major)]+=1\n",
    "#     for index in range(len(y)):\n",
    "#         conf[np.argmax(y[index])][np.argmax(yh[index])]+=1\n",
    "\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"model_full_major_10k_0.54.csv\",\"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
